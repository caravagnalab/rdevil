import scanpy as sc
import patsy as ptsy
import torch
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd


import sys
sys.path.append("../")
%reload_ext autoreload
%autoreload 2

import pydevil


counts = pd.read_csv("../../../../../../counts.csv")
meta = pd.read_csv("../../../../../../meta.csv")


gene_names = list(counts.iloc[:,0])
obs_names = list(meta.iloc[:,0])
X = torch.tensor(counts.iloc[:,0:].values).t()


meta['DiseaseSubtype'] = meta['DiseaseSubtype'].astype(str)


covariates = ptsy.dmatrix("~ -0 + DiseaseSubtype + Sex", meta)
group_matrix = ptsy.dmatrix("~ Individual - 1", meta)


import sys
sys.path.append("../")
%reload_ext autoreload
%autoreload 2
import pydevil


res  = pydevil.run_SVDE(
    X, 
    covariates, 
    gene_names = gene_names,
    cell_names = obs_names, 
    size_factors = False,
    group_matrix = group_matrix,
<<<<<<< HEAD
    variance="Hessian",
=======
    variance="VI_Estimate",
>>>>>>> f622db1 (m)
    jit_compile=True,
    optimizer_name = "ClippedAdam", 
    lr = 0.5, 
    gamma_lr=1e-4, 
    steps = 10, 
    batch_size=1000,
    full_cov = True, 
    cuda = False,
    gauss_loc=5
)


<<<<<<< HEAD
res['params']['random_effects'][1,] - res['params']['random_effects'][1,].mean()
=======
gene_idx = 0


coeff = res['params']['beta']


obs, model_matrix, c, size_factors = X[:,gene_idx], covariates, coeff[:,gene_idx], res['params']['size_factors']


b, m = pydevil.compute_bread_and_meat(torch.tensor(obs), torch.tensor(model_matrix), torch.tensor(c), torch.tensor(res['params']['theta'][gene_idx]), torch.tensor(size_factors))


pydevil.compute_hessian(torch.tensor(obs), torch.tensor(model_matrix), torch.tensor(c), 1 / torch.tensor(res['params']['theta'][gene_idx]))


b


m
>>>>>>> f622db1 (m)


pydevil.test_posterior_null(res, [0,1,-1,0])


contrast = np.array([0,1,-1,0])
cov_d = res['params']['variance']





denominator = np.dot(np.dot(contrast.T, cov_d), contrast)


denominator[1]





inference_res = res
contrast = torch.tensor([0,1,-1,0])


mu_test = (torch.tensor(inference_res["params"]["beta"]) * contrast.reshape([-1,1])).sum(axis = 0)


X = contrast
V = torch.tensor(inference_res["params"]["variance"])


N = torch.tensor(V).size(0)  # Get the size of the first dimension

# Reshape X to (4, 1) to make it compatible with matrix multiplication
X_reshaped = contrast.view(4, 1).double()

# Perform the desired operation for each element in the first dimension of V
result = torch.empty(N)

for i in range(N):
    result[i] = torch.mm(torch.mm(X_reshaped.t(), V[i,:,:]), X_reshaped)


result[1]


V = inference_res["params"]["variance"]
N = V.shape[0]
contrast = contrast.reshape([-1,1]).double()


contrast.T.dtype


total_variance = (contrast.T @ V @ contrast).reshape(-1)


total_variance[1], result[1]





p = 1 - torch.distributions.Chi2(1).cdf(mu_test**2 / total_variance)


p.shape


V[1,:,:]


plt.plot(torch.log10(torch.tensor(res['loss'])))


plt.plot(1 / res['params']['theta'])


res['params']['theta']


torch.max(torch.tensor(res['params']['theta']))


torch.log(torch.tensor(.1))


plt.hist(torch.tensor(res['params']['theta']), bins=100)
